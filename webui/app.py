"""
å‰ä»–è°±AI - Streamlit Webç•Œé¢
åŠŸèƒ½ï¼šä¸Šä¼ è§†é¢‘æ–‡ä»¶ï¼Œè‡ªåŠ¨ç”Ÿæˆå‰ä»–è°±å’Œæ¼”å¥è¯´æ˜
"""

import streamlit as st
import os
import sys
import tempfile
import logging
from pathlib import Path
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime

# å¼ºåˆ¶å°†é¡¹ç›®æ ¹ç›®å½•æ’å…¥åˆ°sys.pathæœ€å‰é¢
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from app.audio_processing import process_video_to_audio_with_beats
from app.pitch_detection import predict_pitch
from app.chord_analysis import analyze_chords_simple
from app.tab_generator import generate_tab_simple
from app.explanation_generator import generate_explanation_simple
from app.enhanced_tab_generator import EnhancedTabGenerator
from config import WEB_CONFIG, AUDIO_CONFIG, PITCH_CONFIG


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å‰ä»–è°±AI - æ™ºèƒ½è°±å­ç”Ÿæˆå™¨",
    page_icon="ğŸ¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2c3e50;
        margin-bottom: 1rem;
    }
    .info-box {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #ffc107;
        margin: 1rem 0;
    }
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
        margin: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)


def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'processing_complete' not in st.session_state:
        st.session_state.processing_complete = False
    if 'results' not in st.session_state:
        st.session_state.results = {}
    if 'uploaded_file' not in st.session_state:
        st.session_state.uploaded_file = None


def validate_uploaded_file(uploaded_file):
    """éªŒè¯ä¸Šä¼ çš„æ–‡ä»¶"""
    if uploaded_file is None:
        return False, "è¯·é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶"
    
    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
    allowed_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.wav', '.mp3', '.flac']
    file_extension = Path(uploaded_file.name).suffix.lower()
    
    if file_extension not in allowed_extensions:
        return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_extension}ã€‚æ”¯æŒçš„æ ¼å¼: {', '.join(allowed_extensions)}"
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    max_size = WEB_CONFIG['upload_max_size']
    if uploaded_file.size > max_size:
        return False, f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {uploaded_file.size / (1024*1024):.1f}MB > {max_size / (1024*1024):.1f}MB"
    
    return True, "æ–‡ä»¶éªŒè¯é€šè¿‡"


def process_video_file(uploaded_file):
    """å¤„ç†è§†é¢‘æ–‡ä»¶"""
    with st.spinner("æ­£åœ¨å¤„ç†è§†é¢‘æ–‡ä»¶..."):
        try:
            # å¯¼å…¥å¿…è¦çš„åº“
            import numpy as np
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            # 1. éŸ³é¢‘å¤„ç†
            st.info("æ­¥éª¤ 1/5: æå–éŸ³é¢‘å¹¶æ£€æµ‹èŠ‚æ‹...")
            audio, sr, tempo, beats = process_video_to_audio_with_beats(
                video_path=tmp_file_path,
                target_sr=AUDIO_CONFIG['sample_rate']
            )
            
            # 2. éŸ³é«˜æ£€æµ‹
            st.info("æ­¥éª¤ 2/5: è¿›è¡ŒéŸ³é«˜æ£€æµ‹...")
            time, frequency, confidence = predict_pitch(
                audio=audio,
                sr=sr,
                model_capacity=PITCH_CONFIG['model_capacity'],
                min_confidence=PITCH_CONFIG['confidence_threshold']
            )
            
            # 3. å’Œå¼¦åˆ†æ
            st.info("æ­¥éª¤ 3/5: åˆ†æå’Œå¼¦è¿›è¡Œ...")
            chord_segments = analyze_chords_simple(
                time=time,
                frequency=frequency,
                confidence=confidence,
                time_window=1.0,
                min_confidence=0.5
            )
            
            # 4. ç”Ÿæˆå…­çº¿è°±
            st.info("æ­¥éª¤ 4/5: ç”Ÿæˆå…­çº¿è°±...")
            # ç”ŸæˆåŸºç¡€å…­çº¿è°±
            tab_text = generate_tab_simple(
                time=time,
                frequency=frequency,
                confidence=confidence,
                output_path=None,  # ä¸ä¿å­˜æ–‡ä»¶ï¼Œåªè¿”å›æ–‡æœ¬
                tuning="standard",
                tempo=tempo
            )
            
            # ç”Ÿæˆå¢å¼ºç‰ˆå…­çº¿è°±
            st.info("æ­£åœ¨ç”Ÿæˆä¸“ä¸šæ ¼å¼å…­çº¿è°±...")
            try:
                enhanced_generator = EnhancedTabGenerator(tuning="standard")
                enhanced_tab_text = enhanced_generator._generate_empty_tab_template()
                
                # å¦‚æœæœ‰éŸ³ç¬¦æ•°æ®ï¼Œå°è¯•ç”ŸæˆçœŸå®å†…å®¹
                if len(frequency) > 0:
                    # è¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥å¤„ç†éŸ³ç¬¦æ•°æ®
                    enhanced_tab_text += "\n\n" + "="*60 + "\n"
                    enhanced_tab_text += "åŸºäºæ‚¨çš„éŸ³é¢‘ç”Ÿæˆçš„å…­çº¿è°±å†…å®¹:\n"
                    enhanced_tab_text += "="*60 + "\n\n"
                    enhanced_tab_text += tab_text
                    
            except Exception as e:
                enhanced_tab_text = tab_text  # å¦‚æœå¢å¼ºç‰ˆå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€ç‰ˆ
            
            # 5. ç”Ÿæˆæ¼”å¥è¯´æ˜
            st.info("æ­¥éª¤ 5/5: ç”Ÿæˆæ¼”å¥è¯´æ˜...")
            try:
                explanation = generate_explanation_simple(
                    chord_segments=chord_segments,
                    tempo=tempo,
                    time_signature="4/4",
                    output_path=None  # ä¸ä¿å­˜æ–‡ä»¶ï¼Œåªè¿”å›æ–‡æœ¬
                )
            except Exception as e:
                explanation = f"æ¼”å¥è¯´æ˜ç”Ÿæˆå¤±è´¥: {str(e)}\n\nå¦‚éœ€AIæ¼”å¥è¯´æ˜ï¼Œè¯·è®¾ç½®OpenAI APIå¯†é’¥ã€‚"
                st.warning("æ¼”å¥è¯´æ˜ç”Ÿæˆå¤±è´¥ï¼Œä½†å…¶ä»–åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(tmp_file_path)
            
            # æ•´ç†ç»“æœ - ç¡®ä¿æ‰€æœ‰numpyæ•°ç»„éƒ½è¢«å®‰å…¨å¤„ç†
            results = {
                'audio': np.array(audio) if audio is not None else np.array([]),
                'sample_rate': int(sr) if sr is not None else 22050,
                'tempo': float(tempo) if tempo is not None else 120.0,
                'beats': np.array(beats) if beats is not None else np.array([]),
                'time': np.array(time) if time is not None else np.array([]),
                'frequency': np.array(frequency) if frequency is not None else np.array([]),
                'confidence': np.array(confidence) if confidence is not None else np.array([]),
                'chord_segments': chord_segments if chord_segments is not None else [],
                'tab_text': str(tab_text) if tab_text is not None else "",
                'enhanced_tab_text': str(enhanced_tab_text) if 'enhanced_tab_text' in locals() else str(tab_text),
                'explanation': str(explanation) if explanation is not None else "",
                'duration': float(len(audio) / sr) if audio is not None and sr > 0 else 0.0,
                'filename': str(uploaded_file.name)
            }
            
            st.success("å¤„ç†å®Œæˆï¼")
            return results
            
        except Exception as e:
            error_msg = str(e)
            st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {error_msg}")
            
            # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
            with st.expander("è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                st.code(error_msg)
                import traceback
                st.code(traceback.format_exc())
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if 'tmp_file_path' in locals():
                try:
                    os.unlink(tmp_file_path)
                except:
                    pass
            return None


def display_audio_info(results):
    """æ˜¾ç¤ºéŸ³é¢‘ä¿¡æ¯"""
    st.subheader("ğŸ“Š éŸ³é¢‘ä¿¡æ¯")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æ—¶é•¿", f"{results['duration']:.1f}ç§’")
    
    with col2:
        st.metric("é‡‡æ ·ç‡", f"{results['sample_rate']}Hz")
    
    with col3:
        st.metric("é€Ÿåº¦", f"{results['tempo']:.1f} BPM")
    
    with col4:
        valid_frames = np.sum(results['confidence'] > 0.5)
        total_frames = len(results['confidence'])
        detection_rate = (valid_frames / total_frames) * 100
        st.metric("æ£€æµ‹ç‡", f"{detection_rate:.1f}%")


def plot_pitch_contour(results):
    """ç»˜åˆ¶éŸ³é«˜è½®å»“å›¾"""
    st.subheader("ğŸµ éŸ³é«˜è½®å»“")
    
    # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
    valid_mask = results['confidence'] > 0.5
    valid_time = results['time'][valid_mask]
    valid_freq = results['frequency'][valid_mask]
    valid_conf = results['confidence'][valid_mask]
    
    if len(valid_time) == 0:
        st.warning("æ²¡æœ‰æ£€æµ‹åˆ°æœ‰æ•ˆçš„éŸ³é«˜æ•°æ®")
        return
    
    # åˆ›å»ºéŸ³é«˜è½®å»“å›¾
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=valid_time,
        y=valid_freq,
        mode='lines+markers',
        name='éŸ³é«˜',
        line=dict(color='#1f77b4', width=2),
        marker=dict(size=4, color=valid_conf, colorscale='Viridis', showscale=True)
    ))
    
    # æ·»åŠ èŠ‚æ‹çº¿
    if len(results['beats']) > 0:
        for beat in results['beats']:
            fig.add_vline(x=beat, line_dash="dash", line_color="red", opacity=0.5)
    
    fig.update_layout(
        title="éŸ³é«˜éšæ—¶é—´å˜åŒ–",
        xaxis_title="æ—¶é—´ (ç§’)",
        yaxis_title="é¢‘ç‡ (Hz)",
        height=400,
        showlegend=True
    )
    
    st.plotly_chart(fig, use_container_width=True)


def plot_chord_progression(results):
    """ç»˜åˆ¶å’Œå¼¦è¿›è¡Œå›¾"""
    st.subheader("ğŸ¼ å’Œå¼¦è¿›è¡Œ")
    
    if not results['chord_segments']:
        st.warning("æ²¡æœ‰æ£€æµ‹åˆ°å’Œå¼¦")
        return
    
    # å‡†å¤‡å’Œå¼¦æ•°æ®
    chord_data = []
    for segment in results['chord_segments']:
        chord_data.append({
            'start_time': segment['start_time'],
            'end_time': segment['end_time'],
            'chord': segment['chord'],
            'duration': segment['duration'],
            'confidence': segment['confidence']
        })
    
    df = pd.DataFrame(chord_data)
    
    # åˆ›å»ºå’Œå¼¦è¿›è¡Œå›¾
    fig = go.Figure()
    
    for i, row in df.iterrows():
        fig.add_trace(go.Bar(
            x=[row['duration']],
            y=[row['chord']],
            orientation='h',
            name=row['chord'],
            text=f"{row['chord']}<br>{row['duration']:.1f}s",
            textposition='auto',
            hovertemplate=f"å’Œå¼¦: {row['chord']}<br>æ—¶é•¿: {row['duration']:.1f}ç§’<br>ç½®ä¿¡åº¦: {row['confidence']:.2f}<extra></extra>"
        ))
    
    fig.update_layout(
        title="å’Œå¼¦è¿›è¡Œæ—¶é—´çº¿",
        xaxis_title="æ—¶é•¿ (ç§’)",
        yaxis_title="å’Œå¼¦",
        height=300,
        showlegend=False,
        barmode='stack'
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # æ˜¾ç¤ºå’Œå¼¦ç»Ÿè®¡
    chord_counts = df['chord'].value_counts()
    st.write("å’Œå¼¦å‡ºç°é¢‘ç‡:")
    st.bar_chart(chord_counts)


def display_tab_text(results):
    """æ˜¾ç¤ºå…­çº¿è°±æ–‡æœ¬"""
    st.subheader("ğŸ¸ ä¸“ä¸šå…­çº¿è°±")
    
    # é€‰æ‹©æ˜¾ç¤ºæ ¼å¼
    tab_format = st.radio(
        "é€‰æ‹©å…­çº¿è°±æ ¼å¼:",
        ["ä¸“ä¸šæ ¼å¼", "æ ‡å‡†æ ¼å¼"],
        horizontal=True
    )
    
    # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºä¸åŒæ ¼å¼
    if tab_format == "ä¸“ä¸šæ ¼å¼":
        tab_content = results.get('enhanced_tab_text', results['tab_text'])
        st.markdown("**ä¸“ä¸šçº§å…­çº¿è°± - åŒ…å«å’Œå¼¦æ ‡è®°ã€å°èŠ‚çº¿å’Œæ¸…æ™°æ ¼å¼**")
    else:
        tab_content = results['tab_text']
        st.markdown("**æ ‡å‡†ASCIIå…­çº¿è°±**")
    
    # åˆ›å»ºå¯æ»šåŠ¨çš„æ–‡æœ¬æ¡†
    tab_container = st.container()
    with tab_container:
        st.text_area(
            "ç”Ÿæˆçš„å…­çº¿è°±",
            value=tab_content,
            height=500,
            disabled=True
        )
    
    # ä¸‹è½½æŒ‰é’®
    col1, col2 = st.columns(2)
    
    with col1:
        # ä¸‹è½½TXTæ–‡ä»¶
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å…­çº¿è°± (TXT)",
            data=results['tab_text'],
            file_name=f"guitar_tab_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain"
        )
    
    with col2:
        # ä¸‹è½½æŒ‰é’®ï¼ˆå ä½ç¬¦ï¼Œå®é™…PDFç”Ÿæˆéœ€è¦é¢å¤–åº“ï¼‰
        st.info("PDFä¸‹è½½åŠŸèƒ½éœ€è¦å®‰è£…reportlabåº“")


def display_explanation(results):
    """æ˜¾ç¤ºæ¼”å¥è¯´æ˜"""
    st.subheader("ğŸ“ æ¼”å¥è¯´æ˜")
    
    # æ˜¾ç¤ºmarkdownæ ¼å¼çš„è¯´æ˜
    st.markdown(results['explanation'])
    
    # ä¸‹è½½æŒ‰é’®
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½æ¼”å¥è¯´æ˜ (MD)",
        data=results['explanation'],
        file_name=f"playing_guide_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
        mime="text/markdown"
    )


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    init_session_state()
    
    # é¡µé¢æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ¸ å‰ä»–è°±AI</h1>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; font-size: 1.2rem; color: #666;">æ™ºèƒ½è§†é¢‘è½¬å‰ä»–è°±ç”Ÿæˆå™¨</p>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        
        # æ¨¡å‹è®¾ç½®
        st.subheader("æ¨¡å‹å‚æ•°")
        model_capacity = st.selectbox(
            "CREPEæ¨¡å‹ç²¾åº¦",
            ["tiny", "small", "medium", "large", "full"],
            index=2,
            help="ç²¾åº¦è¶Šé«˜ï¼Œå¤„ç†è¶Šæ…¢"
        )
        
        confidence_threshold = st.slider(
            "ç½®ä¿¡åº¦é˜ˆå€¼",
            min_value=0.1,
            max_value=0.9,
            value=0.5,
            step=0.1,
            help="è¿‡æ»¤ä½ç½®ä¿¡åº¦çš„æ£€æµ‹ç»“æœ"
        )
        
        # å’Œå¼¦åˆ†æè®¾ç½®
        st.subheader("å’Œå¼¦åˆ†æ")
        time_window = st.slider(
            "æ—¶é—´çª—å£ (ç§’)",
            min_value=0.5,
            max_value=3.0,
            value=1.0,
            step=0.1,
            help="å’Œå¼¦åˆ†æçš„æ—¶é—´çª—å£å¤§å°"
        )
        
        # å…­çº¿è°±è®¾ç½®
        st.subheader("å…­çº¿è°±è®¾ç½®")
        tuning = st.selectbox(
            "è°ƒå¼¦æ–¹å¼",
            ["standard", "drop_d", "open_g", "open_d", "dadgad"],
            index=0,
            help="é€‰æ‹©å‰ä»–è°ƒå¼¦æ–¹å¼"
        )
        
        # å¤„ç†æŒ‰é’®
        st.markdown("---")
        process_button = st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary", use_container_width=True)
    
    # ä¸»ç•Œé¢
    if not st.session_state.processing_complete:
        # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
        st.header("ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
        
        uploaded_file = st.file_uploader(
            "é€‰æ‹©è§†é¢‘æˆ–éŸ³é¢‘æ–‡ä»¶",
            type=['mp4', 'mov', 'avi', 'mkv', 'wav', 'mp3', 'flac'],
            help="æ”¯æŒè§†é¢‘å’ŒéŸ³é¢‘æ–‡ä»¶ï¼Œæœ€å¤§100MB"
        )
        
        if uploaded_file:
            # éªŒè¯æ–‡ä»¶
            is_valid, message = validate_uploaded_file(uploaded_file)
            
            if is_valid:
                st.success(message)
                
                # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
                file_info = st.container()
                with file_info:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("æ–‡ä»¶å", uploaded_file.name)
                    with col2:
                        st.metric("æ–‡ä»¶å¤§å°", f"{uploaded_file.size / (1024*1024):.1f}MB")
                    with col3:
                        st.metric("æ–‡ä»¶ç±»å‹", Path(uploaded_file.name).suffix.upper())
                
                # å¤„ç†æŒ‰é’®
                if process_button:
                    # æ›´æ–°é…ç½®
                    PITCH_CONFIG['model_capacity'] = model_capacity
                    PITCH_CONFIG['confidence_threshold'] = confidence_threshold
                    
                    # å¤„ç†æ–‡ä»¶
                    results = process_video_file(uploaded_file)
                    
                    if results:
                        st.session_state.results = results
                        st.session_state.processing_complete = True
                        st.session_state.uploaded_file = uploaded_file
                        st.rerun()
            else:
                st.error(message)
    
    else:
        # æ˜¾ç¤ºå¤„ç†ç»“æœ
        results = st.session_state.results
        
        # æˆåŠŸæ¶ˆæ¯
        st.markdown('<div class="success-box">âœ… æ–‡ä»¶å¤„ç†å®Œæˆï¼ä»¥ä¸‹æ˜¯åˆ†æç»“æœï¼š</div>', unsafe_allow_html=True)
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“Š æ¦‚è§ˆ", "ğŸµ éŸ³é«˜åˆ†æ", "ğŸ¼ å’Œå¼¦åˆ†æ", "ğŸ¸ å…­çº¿è°±", "ğŸ“ æ¼”å¥è¯´æ˜"])
        
        with tab1:
            # æ¦‚è§ˆé¡µé¢
            st.header("ğŸ“Š åˆ†ææ¦‚è§ˆ")
            
            # éŸ³é¢‘ä¿¡æ¯
            display_audio_info(results)
            
            # ç»Ÿè®¡ä¿¡æ¯
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ğŸ“ˆ æ£€æµ‹ç»Ÿè®¡")
                valid_frames = np.sum(results['confidence'] > 0.5)
                total_frames = len(results['confidence'])
                
                st.metric("æ€»å¸§æ•°", total_frames)
                st.metric("æœ‰æ•ˆå¸§æ•°", valid_frames)
                st.metric("æ£€æµ‹ç‡", f"{(valid_frames/total_frames)*100:.1f}%")
                st.metric("æ£€æµ‹åˆ°çš„å’Œå¼¦æ•°", len(results['chord_segments']))
            
            with col2:
                st.subheader("ğŸ¯ è´¨é‡è¯„ä¼°")
                valid_conf = results['confidence'][results['confidence'] > 0]
                valid_freq = results['frequency'][results['frequency'] > 0]
                
                if len(valid_conf) > 0:
                    avg_confidence = np.mean(valid_conf)
                else:
                    avg_confidence = 0.0
                    
                if len(valid_freq) > 0:
                    freq_range = np.max(results['frequency']) - np.min(valid_freq)
                else:
                    freq_range = 0.0
                
                st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.3f}")
                st.metric("é¢‘ç‡èŒƒå›´", f"{freq_range:.1f}Hz")
                
                if len(valid_freq) > 0:
                    st.metric("æœ€é«˜é¢‘ç‡", f"{np.max(results['frequency']):.1f}Hz")
                    st.metric("æœ€ä½é¢‘ç‡", f"{np.min(valid_freq):.1f}Hz")
                else:
                    st.metric("æœ€é«˜é¢‘ç‡", "æ— æ•°æ®")
                    st.metric("æœ€ä½é¢‘ç‡", "æ— æ•°æ®")
        
        with tab2:
            # éŸ³é«˜åˆ†æé¡µé¢
            st.header("ğŸµ éŸ³é«˜åˆ†æ")
            plot_pitch_contour(results)
        
        with tab3:
            # å’Œå¼¦åˆ†æé¡µé¢
            st.header("ğŸ¼ å’Œå¼¦åˆ†æ")
            plot_chord_progression(results)
        
        with tab4:
            # å…­çº¿è°±é¡µé¢
            st.header("ğŸ¸ å…­çº¿è°±")
            display_tab_text(results)
        
        with tab5:
            # æ¼”å¥è¯´æ˜é¡µé¢
            st.header("ğŸ“ æ¼”å¥è¯´æ˜")
            display_explanation(results)
        
        # é‡æ–°å¤„ç†æŒ‰é’®
        st.markdown("---")
        if st.button("ğŸ”„ é‡æ–°å¤„ç†", use_container_width=True):
            st.session_state.processing_complete = False
            st.session_state.results = {}
            st.session_state.uploaded_file = None
            st.rerun()


if __name__ == "__main__":
    main() 